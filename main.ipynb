{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docs with name is the input docs, the docs start with MSR is the output docs. \n",
    "\n",
    "I want to create a python streamlit app, that let the managers input the inputs docs, then it will look at each input doc. \n",
    "\n",
    "Process:\n",
    "\n",
    "* Create a master file: just a variable in the script. (save to a word or text file later)\n",
    "   a. Look into each file,\n",
    "       a. extract the file name.\n",
    "       b. extract the data from the file.\n",
    "   b. Do the same for all input docs.\n",
    "\n",
    "\n",
    "* Create output docs\n",
    "   1. Dumb all into llm: \n",
    "      1. Sonnet: 1 hallucination\n",
    "      2. Gemini:\n",
    "   2. By task order\n",
    "\n",
    "Design decisions:\n",
    "- Do one task order at a time, instead of dumb all files in at once.\n",
    "  - Why: \n",
    "    - Simplified the task: avoid complexity manage files.\n",
    "    - Reduce risk of hallucination for super long context. \n",
    "\n",
    "Edge case:\n",
    "- Some person may not have the report: \n",
    "    - Administrative Services Support   \n",
    "        Kyerra Jones\n",
    "        o\tNO INPUT DOCUMENT\n",
    "- Make sure their name is on the file name: \"MSR TO1 BernardonL September 24.docx\"\n",
    "- Highlight the accuracy of the information in the prompt!!! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing:\n",
    "- Create a good example file.\n",
    "- Combined all docx files into 1 file.\n",
    "- Upload to LLM with example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install python-docx google-generativeai python-dotenv pypandoc anthropic openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload TO files\n",
    "- Extract text from docx file into 1 master file\n",
    "- Pass the master file with example file to LLM\n",
    "- Output the MSR file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell: Organize Input Files by Task Order and Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "def get_task_order_info(file_path):\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        task_order_info = None\n",
    "        division_info = None\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if \"Task Order\" in paragraph.text:\n",
    "                task_order_info = paragraph.text.strip()\n",
    "            if \"Division\" in paragraph.text:\n",
    "                division_info = paragraph.text.strip()\n",
    "            if task_order_info and division_info:\n",
    "                break\n",
    "        \n",
    "        if task_order_info and division_info:\n",
    "            to_match = re.search(r'Task Order (\\d+)', task_order_info)\n",
    "            to_number = to_match.group(1) if to_match else \"\"\n",
    "            \n",
    "            division_full = division_info.strip()\n",
    "            short_name_match = re.search(r'\\(([^)]+)\\)', division_full)\n",
    "            short_name = short_name_match.group(1) if short_name_match else \"\"\n",
    "            \n",
    "            return to_number, short_name, division_full.replace('('+short_name+')', '').strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {file_path}. Error: {e}\")\n",
    "    return None, None, None\n",
    "\n",
    "# The rest of the script remains the same\n",
    "\n",
    "def organize_files(input_dir, output_base_dir):\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            to_number, short_name, division_full = get_task_order_info(file_path)\n",
    "            \n",
    "            if to_number and short_name and division_full:\n",
    "                # Create folder name\n",
    "                folder_name = f\"TO{to_number}_{short_name}_{division_full.replace(' ', '')}\"\n",
    "                output_dir = os.path.join(output_base_dir, folder_name)\n",
    "                \n",
    "                # Create the output directory if it doesn't exist\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                # Move the file\n",
    "                shutil.move(file_path, os.path.join(output_dir, filename))\n",
    "                print(f\"Moved {filename} to {output_dir}\")\n",
    "            else:\n",
    "                print(f\"Could not determine task order info for {filename}\")\n",
    "\n",
    "# Usage\n",
    "input_directory = \"./data_files/inputs/all\"\n",
    "output_base_directory = \"./data_files/inputs\"\n",
    "\n",
    "organize_files(input_directory, output_base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MSR from input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined documents exported to: ./data_files/master_file/master_file.txt\n",
      "Monthly Status Report has been generated using gpt4 and saved to './data_files/outputs/TO4_LFD_LeasedFacilitiesDivision_gpt4.docx'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Monthly Status Report # --\n",
       "\n",
       "**HQ0034-20-F-0237**  \n",
       "**Task Order 4**  \n",
       "**Leased Facilities Division (LFD)**  \n",
       "**Administrative and Financial Services Support**\n",
       "\n",
       "## For Work Performed:  \n",
       "**September 2024**  \n",
       "\n",
       "### Submitted to:  \n",
       "Mrs. Tina Hall  \n",
       "Contracting Officerâ€™s Representative  \n",
       "Washington Headquarters Service (WHS)  \n",
       "Acquisition Directorate (AD)  \n",
       "1155 Defense Pentagon Room 5B951  \n",
       "Washington, DC 20301-1155  \n",
       "tina.m.hall70.civ@mail.mil  \n",
       "(202) 819-2679\n",
       "\n",
       "### Submitted by:  \n",
       "Adrian Nicholas  \n",
       "Redhorse Corporation  \n",
       "1777 N. Kent St, Suite 1200  \n",
       "Arlington, VA 22209  \n",
       "adrian.nicholas@redhorsecorp.com  \n",
       "(347) 204-8125\n",
       "\n",
       "---\n",
       "\n",
       "## Administrative and Financial Services Support Team  \n",
       "- Eddy Biniam  \n",
       "- Miguel Vega\n",
       "\n",
       "---\n",
       "\n",
       "### Work Performed During September 2024  \n",
       "**Administrative Services Support**  \n",
       "\n",
       "#### Eddy Biniam  \n",
       "- Assisted a colleague in gathering necessary 3 DAI reports and 1 Maximo report to send out a Cost Transfer in a timely fashion.  \n",
       "- Completed a hot item that my Supervisor and lead needed immediately. Did a contract PR for a CMTSS contract for goods, demonstrating the ability to remain calm and focused under pressure and submit the document without any mistakes for immediate signing.  \n",
       "- Worked on the Status of Funds for FY22 and FY23, verifying no funds remained. Communicated findings to my supervisor and edited the Status of Funds data for clarity.  \n",
       "- Completed 2 contract PRs for goods for 20K, providing a solution to my supervisor. Successfully created 2 PRs with my supervisor observing, ensuring visibility in PD2.  \n",
       "- Assisted my supervisor in locating a specific MIPR on the Open Commitment Pivot Tables, ensuring the correct email chain was used to provide the agency (DLA) with the requested MIPR for urgent processing of the 448-2 acceptance.\n",
       "\n",
       "#### Miguel Vega  \n",
       "- Assisted a colleague in gathering necessary 3 DAI reports and 1 Maximo report to send out a Cost Transfer in a timely fashion.  \n",
       "- Completed a hot item that my Supervisor and lead needed immediately. Did a contract PR for a CMTSS contract for goods, demonstrating the ability to remain calm and focused under pressure and submit the document without any mistakes for immediate signing.  \n",
       "- Worked on the Status of Funds for FY22 and FY23, verifying no funds remained. Communicated findings to my supervisor and edited the Status of Funds data for clarity.  \n",
       "- Completed 2 contract PRs for goods for 20K, providing a solution to my supervisor. Successfully created 2 PRs with my supervisor observing, ensuring visibility in PD2.  \n",
       "- Assisted my supervisor in locating a specific MIPR on the Open Commitment Pivot Tables, ensuring the correct email chain was used to provide the agency (DLA) with the requested MIPR for urgent processing of the 448-2 acceptance.\n",
       "\n",
       "---\n",
       "\n",
       "## Deliverables Completed  \n",
       "- Monthly Status Report  \n",
       "- Provided administrative and financial services support.\n",
       "\n",
       "---\n",
       "\n",
       "## Highlights  \n",
       "- None\n",
       "\n",
       "---\n",
       "\n",
       "## Issues/Resolutions  \n",
       "- **Issue:** None  \n",
       "- **Resolution:** None\n",
       "\n",
       "---\n",
       "\n",
       "## Planned Work for Next Two Months  \n",
       "**Administrative Services Support**  \n",
       "- No new bullet points\n",
       "\n",
       "**Financial Services Support**  \n",
       "- No new bullet points\n",
       "\n",
       "---\n",
       "\n",
       "## Leave  \n",
       "| Name         | Planned Leave September | Planned Leave October |\n",
       "|--------------|-------------------------|-----------------------|\n",
       "| Eddy Biniam  | NA                      | NA                    |\n",
       "| Miguel Vega  | NA                      | NA                    |\n",
       "\n",
       "---\n",
       "\n",
       "## Recommendations  \n",
       "- None\n",
       "\n",
       "---\n",
       "\n",
       "## Contractual/Staffing Actions  \n",
       "- None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import pypandoc\n",
    "import anthropic\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup for different AI models\n",
    "def setup_ai_model(model_name: str):\n",
    "    if model_name == \"gemini\":\n",
    "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        generation_config = {\n",
    "            \"temperature\": 0,\n",
    "            \"max_output_tokens\": 8192,\n",
    "        }\n",
    "        \n",
    "        safety_settings = [\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        ]\n",
    "        \n",
    "        return genai.GenerativeModel(\n",
    "            model_name=\"gemini-1.5-pro\",\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "    elif model_name == \"claude\":\n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        return anthropic.Anthropic(api_key=api_key)\n",
    "    elif model_name == \"gpt4\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        return openai.OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "# Generate monthly status report\n",
    "def generate_monthly_status_report(model_name: str, master_content: str, example_content: str) -> str:\n",
    "    # Load the prompt from the file\n",
    "    prompt = load_prompt(\"monthly_status_report\")\n",
    "    \n",
    "    # Format the prompt with the variables\n",
    "    formatted_prompt = prompt.format(\n",
    "        master_content=master_content,\n",
    "        example_content=example_content\n",
    "    )\n",
    "    \n",
    "    model = setup_ai_model(model_name)\n",
    "    \n",
    "    try:\n",
    "        if model_name == \"gemini\":\n",
    "            response = model.generate_content(formatted_prompt, stream=True)\n",
    "            full_response = \"\"\n",
    "            for chunk in response:\n",
    "                if chunk.text:\n",
    "                    full_response += chunk.text\n",
    "            \n",
    "            # Handling Safety Filters\n",
    "            if response.candidates[0].finish_reason == \"SAFETY\":\n",
    "                safety_ratings = response.candidates[0].safety_ratings\n",
    "                safety_message = \"Content was filtered due to safety concerns:\\n\"\n",
    "                for rating in safety_ratings:\n",
    "                    safety_message += f\"- Category: {rating.category}, Probability: {rating.probability}\\n\"\n",
    "                print(safety_message)\n",
    "                return safety_message\n",
    "            \n",
    "            # Retrieving Usage Metadata\n",
    "            if hasattr(response, 'usage_metadata'):\n",
    "                prompt_tokens = response.usage_metadata.prompt_token_count\n",
    "                candidates_tokens = response.usage_metadata.candidates_token_count\n",
    "                print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "                print(f\"Response tokens: {candidates_tokens}\")\n",
    "            \n",
    "            return full_response\n",
    "        \n",
    "        elif model_name == \"claude\":\n",
    "            response = model.messages.create(\n",
    "                model=\"claude-3-sonnet-20240229\",\n",
    "                max_tokens=4096,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": formatted_prompt\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            return response.content[0].text\n",
    "        \n",
    "        elif model_name == \"gpt4\":\n",
    "            response = model.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "                max_tokens=4096,\n",
    "                temperature=0\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {e}\"\n",
    "        print(error_message)\n",
    "        return error_message\n",
    "\n",
    "# File processing functions\n",
    "def read_word_file(file_path: str) -> str:\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def process_input_docs(directory: str) -> Dict[str, str]:\n",
    "    input_docs = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            content = read_word_file(file_path)\n",
    "            input_docs[filename] = content\n",
    "    return input_docs\n",
    "\n",
    "# Prompt management functions\n",
    "def load_prompt(prompt_name: str) -> str:\n",
    "    prompt_folder = \"./prompts\"\n",
    "    prompt_path = os.path.join(prompt_folder, f\"{prompt_name}.txt\")\n",
    "    \n",
    "    if os.path.exists(prompt_path):\n",
    "        with open(prompt_path, 'r') as file:\n",
    "            return file.read()\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Prompt file '{prompt_name}.txt' not found in the prompts folder.\")\n",
    "\n",
    "# File saving and conversion functions\n",
    "def save_markdown_to_file(markdown_content: str, file_path: str):\n",
    "    with open(file_path, 'w') as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "def convert_markdown_to_docx(markdown_file_path: str, output_file_path: str):\n",
    "    pypandoc.convert_file(markdown_file_path, 'docx', outputfile=output_file_path)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Process input documents\n",
    "    input_directory = \"./data_files/inputs/TO1_FFD_FederalFacilitiesDivision\"\n",
    "    processed_docs = process_input_docs(input_directory)\n",
    "\n",
    "    # Export into a text file in the data_files/master_file folder\n",
    "    os.makedirs(\"./data_files/master_file\", exist_ok=True)\n",
    "    output_file = \"./data_files/master_file/master_file.txt\"\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        for filename, content in processed_docs.items():\n",
    "            file.write(f\"File: {filename}\\n\")\n",
    "            file.write(f\"Content: {content}\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")\n",
    "            file.write(\"\\n\\n\")\n",
    "\n",
    "    print(f\"Combined documents exported to: {output_file}\")\n",
    "\n",
    "    # Read the master file and example file\n",
    "    with open(\"./data_files/master_file/master_file.txt\", 'r') as file:\n",
    "        master_content = file.read()\n",
    "\n",
    "    with open(\"./example/example.txt\", 'r') as file:\n",
    "        example_content = file.read()\n",
    "\n",
    "    # Let user select the model\n",
    "    model_choice = input(\"Choose a model (gemini/claude/gpt4): \").lower()\n",
    "    while model_choice not in [\"gemini\", \"claude\", \"gpt4\"]:\n",
    "        print(\"Invalid choice. Please choose gemini, claude, or gpt4.\")\n",
    "        model_choice = input(\"Choose a model (gemini/claude/gpt4): \").lower()\n",
    "\n",
    "    # Generate the monthly status report in Markdown\n",
    "    report = generate_monthly_status_report(model_choice, master_content, example_content)\n",
    "\n",
    "    # Create outputs folder if it doesn't exist\n",
    "    os.makedirs(\"./data_files/outputs\", exist_ok=True)\n",
    "\n",
    "    # Get the input folder name\n",
    "    input_folder_name = os.path.basename(input_directory)\n",
    "\n",
    "    # Save the Markdown report\n",
    "    markdown_file = f\"./data_files/outputs/{input_folder_name}_{model_choice}.md\"\n",
    "    save_markdown_to_file(report, markdown_file)\n",
    "\n",
    "    # Convert the Markdown report to Word document\n",
    "    docx_file = f\"./data_files/outputs/{input_folder_name}_{model_choice}.docx\"\n",
    "    convert_markdown_to_docx(markdown_file, docx_file)\n",
    "\n",
    "    print(f\"Monthly Status Report has been generated using {model_choice} and saved to '{docx_file}'\")\n",
    "\n",
    "    # Display the generated report (if running in a Jupyter notebook)\n",
    "    with open(markdown_file, 'r') as md_file:\n",
    "        generated_report_content = md_file.read()\n",
    "    display(Markdown(generated_report_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

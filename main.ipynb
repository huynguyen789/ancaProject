{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docs with name is the input docs, the docs start with MSR is the output docs. \n",
    "\n",
    "I want to create a python streamlit app, that let the managers input the inputs docs, then it will look at each input doc. \n",
    "\n",
    "Process:\n",
    "\n",
    "* Create a master file: just a variable in the script. (save to a word or text file later)\n",
    "   a. Look into each file,\n",
    "       a. extract the file name.\n",
    "       b. extract the data from the file.\n",
    "   b. Do the same for all input docs.\n",
    "\n",
    "\n",
    "* Create output docs\n",
    "   1. Dumb all into llm: \n",
    "      1. Sonnet: 1 hallucination\n",
    "      2. Gemini:\n",
    "   2. By task order\n",
    "\n",
    "Design decisions:\n",
    "- Do one task order at a time, instead of dumb all files in at once.\n",
    "  - Why: \n",
    "    - Simplified the task: avoid complexity manage files.\n",
    "    - Reduce risk of hallucination for super long context. \n",
    "\n",
    "Edge case:\n",
    "- Some person may not have the report: \n",
    "    - Administrative Services Support   \n",
    "        Kyerra Jones\n",
    "        o\tNO INPUT DOCUMENT\n",
    "- Make sure their name is on the file name: \"MSR TO1 BernardonL September 24.docx\"\n",
    "- Highlight the accuracy of the information in the prompt!!! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing:\n",
    "- Create a good example file.\n",
    "- Combined all docx files into 1 file.\n",
    "- Upload to LLM with example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install python-docx google-generativeai python-dotenv pypandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload TO files\n",
    "- Extract text from docx file into 1 master file\n",
    "- Pass the master file with example file to LLM\n",
    "- Output the MSR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined documents exported to: ./data_files/master_file/master_file.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from typing import List, Dict\n",
    "\n",
    "def read_word_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read the content of a Word file.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the Word file\n",
    "    \n",
    "    Returns:\n",
    "    str: Content of the Word file\n",
    "    \"\"\"\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def process_input_docs(directory: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Process all Word files in the given directory.\n",
    "    \n",
    "    Args:\n",
    "    directory (str): Path to the directory containing Word files\n",
    "    \n",
    "    Returns:\n",
    "    Dict[str, str]: A dictionary with filenames as keys and file contents as values\n",
    "    \"\"\"\n",
    "    input_docs = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            content = read_word_file(file_path)\n",
    "            input_docs[filename] = content\n",
    "    return input_docs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = \"./data_files/inputs/TO4_LeasesFacilitiesDivision(LFD)\"\n",
    "    \n",
    "    processed_docs = process_input_docs(input_directory)\n",
    "    \n",
    "    # Export into a text file in the data_files/master_file folder\n",
    "    os.makedirs(\"./data_files/master_file\", exist_ok=True)\n",
    "    output_file = \"./data_files/master_file/master_file.txt\"\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for filename, content in processed_docs.items():\n",
    "            file.write(f\"File: {filename}\\n\")\n",
    "            file.write(f\"Content: {content}\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")\n",
    "            file.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"Combined documents exported to: {output_file}\")\n",
    "    \n",
    "    # # Print the results\n",
    "    # for filename, content in processed_docs.items():\n",
    "    #     print(f\"File: {filename}\")\n",
    "    #     print(f\"Content: {content}\")\n",
    "    #     print(\"-\" * 50)\n",
    "    #     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 3732\n",
      "Response tokens: 863\n",
      "Monthly Status Report has been generated and saved to './generated_report.docx'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "from docx import Document  # Add this import for Word document handling\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import pypandoc\n",
    "\n",
    "\n",
    "# Prompt management\n",
    "def load_prompt(prompt_name: str) -> str:\n",
    "    prompt_folder = \"./prompt_folder\"\n",
    "    os.makedirs(prompt_folder, exist_ok=True)\n",
    "    prompt_path = os.path.join(prompt_folder, f\"{prompt_name}.txt\")\n",
    "    \n",
    "    if os.path.exists(prompt_path):\n",
    "        with open(prompt_path, 'r') as file:\n",
    "            return file.read()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def save_prompt(prompt_name: str, prompt_content: str):\n",
    "    prompt_folder = \"./prompt_folder\"\n",
    "    os.makedirs(prompt_folder, exist_ok=True)\n",
    "    prompt_path = os.path.join(prompt_folder, f\"{prompt_name}.txt\")\n",
    "    \n",
    "    with open(prompt_path, 'w') as file:\n",
    "        file.write(prompt_content)\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Creating a Model\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "def generate_monthly_status_report(master_content: str, example_content: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with creating a Monthly Status Report based on the following information:\n",
    "\n",
    "    1. Master File Content (combined MSR files):\n",
    "    {master_content}\n",
    "\n",
    "    2. Example Report Format (example of a combined MSR file output):\n",
    "    {example_content}\n",
    "\n",
    "    Please generate a Monthly Status Report following the structure and style of the example report, \n",
    "    using the information provided in the master file. \n",
    "    - Ensure that you maintain the accuracy of the information from the master file (only fix grammar, do not change the information)\n",
    "    - Follow the formatting of the example report.\n",
    "    - Make sure to seperated the work of each person.\n",
    "    \n",
    "    Use Markdown to represent the following:\n",
    "    - Headings\n",
    "    - Bullet points\n",
    "    - Bold for emphasis\n",
    "    - Tables where applicable\n",
    "    \n",
    "    Your generated report should be comprehensive, accurate, and well-structured in Markdown format.\n",
    "    \"\"\"\n",
    "    save_prompt(\"monthly_status_report\", prompt)\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt, stream=True)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for chunk in response:\n",
    "            if chunk.text:\n",
    "                full_response += chunk.text\n",
    "        \n",
    "        # Handling Safety Filters\n",
    "        if response.candidates[0].finish_reason == \"SAFETY\":\n",
    "            safety_ratings = response.candidates[0].safety_ratings\n",
    "            safety_message = \"Content was filtered due to safety concerns:\\n\"\n",
    "            for rating in safety_ratings:\n",
    "                safety_message += f\"- Category: {rating.category}, Probability: {rating.probability}\\n\"\n",
    "            print(safety_message)\n",
    "            return safety_message\n",
    "        \n",
    "        # Retrieving Usage Metadata\n",
    "        if hasattr(response, 'usage_metadata'):\n",
    "            prompt_tokens = response.usage_metadata.prompt_token_count\n",
    "            candidates_tokens = response.usage_metadata.candidates_token_count\n",
    "            print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "            print(f\"Response tokens: {candidates_tokens}\")\n",
    "        \n",
    "        return full_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {e}\"\n",
    "        print(error_message)\n",
    "        return error_message\n",
    "\n",
    "\n",
    "\n",
    "# Save the generated Markdown to a file\n",
    "def save_markdown_to_file(markdown_content: str, file_path: str):\n",
    "    with open(file_path, 'w') as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "# Convert Markdown to .docx using pypandoc\n",
    "def convert_markdown_to_docx(markdown_file_path: str, output_file_path: str):\n",
    "    pypandoc.convert_file(markdown_file_path, 'docx', outputfile=output_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the master file and example file\n",
    "    with open(\"./data_files/master_file/master_file.txt\", 'r') as file:\n",
    "        master_content = file.read()\n",
    "    \n",
    "    with open(\"./example/example.txt\", 'r') as file:\n",
    "        example_content = file.read()\n",
    "    \n",
    "    # Generate the monthly status report in Markdown\n",
    "    report = generate_monthly_status_report(master_content, example_content)\n",
    "\n",
    "    # Save the Markdown report\n",
    "    markdown_file = \"./generated_report.md\"\n",
    "    save_markdown_to_file(report, markdown_file)\n",
    "\n",
    "    # Convert the Markdown report to Word document\n",
    "    docx_file = \"./generated_report.docx\"\n",
    "    convert_markdown_to_docx(markdown_file, docx_file)\n",
    "\n",
    "    print(f\"Monthly Status Report has been generated and saved to '{docx_file}'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

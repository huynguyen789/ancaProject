{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docs with name is the input docs, the docs start with MSR is the output docs. \n",
    "\n",
    "I want to create a python streamlit app, that let the managers input the inputs docs, then it will look at each input doc. \n",
    "\n",
    "Process:\n",
    "\n",
    "* Create a master file: just a variable in the script. (save to a word or text file later)\n",
    "   a. Look into each file,\n",
    "       a. extract the file name.\n",
    "       b. extract the data from the file.\n",
    "   b. Do the same for all input docs.\n",
    "\n",
    "\n",
    "* Create output docs\n",
    "   1. Dumb all into llm: \n",
    "      1. Sonnet: 1 hallucination\n",
    "      2. Gemini:\n",
    "   2. By task order\n",
    "\n",
    "Design decisions:\n",
    "- Do one task order at a time, instead of dumb all files in at once.\n",
    "  - Why: \n",
    "    - Simplified the task: avoid complexity manage files.\n",
    "    - Reduce risk of hallucination for super long context. \n",
    "\n",
    "Edge case:\n",
    "- Some person may not have the report: \n",
    "    - Administrative Services Support   \n",
    "        Kyerra Jones\n",
    "        o\tNO INPUT DOCUMENT\n",
    "- Make sure their name is on the file name: \"MSR TO1 BernardonL September 24.docx\"\n",
    "- Highlight the accuracy of the information in the prompt!!! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing:\n",
    "- Create a good example file.\n",
    "- Combined all docx files into 1 file.\n",
    "- Upload to LLM with example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install python-docx google-generativeai python-dotenv pypandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload TO files\n",
    "- Extract text from docx file into 1 master file\n",
    "- Pass the master file with example file to LLM\n",
    "- Output the MSR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined documents exported to: ./data_files/master_file/master_file.txt\n",
      "Prompt tokens: 3807\n",
      "Response tokens: 1257\n",
      "Monthly Status Report has been generated and saved to './generated_report.docx'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "File: MSR 12 HQ0034-20-F-0237 Leased Facilities Division (LFD) September 2024.docx\n",
       "Content:\n",
       "\n",
       "# Monthly Status Report # 12\n",
       "\n",
       "**HQ0034-20-F-0237**  \n",
       "**Task Order 4**  \n",
       "**Leased Facilities Division (LFD)**  \n",
       "**Administrative and Financial Services Support**\n",
       "\n",
       "## For Work Performed:  \n",
       "**September 2024**  \n",
       "\n",
       "### Submitted to:  \n",
       "Mrs. Tina Hall  \n",
       "Contracting Officer’s Representative  \n",
       "Washington Headquarters Service (WHS)  \n",
       "Acquisition Directorate (AD)  \n",
       "1155 Defense Pentagon Room 5B951  \n",
       "Washington, DC 20301-1155  \n",
       "Tina.m.hall70.civ@mail.mil  \n",
       "(202) 819-2679\n",
       "\n",
       "### Submitted by:  \n",
       "Adrian Nicholas  \n",
       "Redhorse Corporation  \n",
       "1777 N. Kent St, Suite 1200  \n",
       "Arlington, VA 22209  \n",
       "adrian.nicholas@redhorsecorp.com  \n",
       "(347) 204-8125\n",
       "\n",
       "---\n",
       "\n",
       "## Administrative and Financial Services Support Team  \n",
       "- Eddy Biniam \n",
       "- Miguel Vega\n",
       "\n",
       "---\n",
       "\n",
       "### Work Performed During September 2024  \n",
       "**Financial Services Support**  \n",
       "\n",
       "#### Eddy Biniam\n",
       "- Assisted a colleague in gathering necessary 3 DAI reports and 1 Maximo report in order to send out a Cost Transfer in a timely fashion.\n",
       "- Completed a hot item that my Supervisor and lead needed immediately: contract PR’s for a CMTSS contract for goods. I was able to demonstrate the ability to remain calm and focused under pressure and submit the document without any mistakes so the document could be signed as soon as possible. I stayed until the task was completed and the supervisor was informed. \n",
       "- Worked on the Status of Funds for FY22 as well as FY23 and verified that there were no funds remaining. Upon accessing DAI and gathering the data, I communicated my findings to my supervisor and edited the Status of Funds data so my supervisor could easily see and read the gathered information. \n",
       "- Completed 2 contract PRs for goods for 20K. I was able to provide a solution to my supervisor. One of my colleagues who was in charge of creating those PRs continued to get an error message. I was able to create 2 PRs with my supervisor looking on to see if they could see it in PD2. The creation of the PR’s was a success and was able to be seen in PD2. Since it is the close of the FY we could not afford to delay due to in-corrections. The corrections were able to be made and did not delay the process. \n",
       "- Worked on assisting my supervisor in looking for a specific MIPR that was on the Open Commitment Pivot Tables I pull and create every morning. I was provided the correct email chain and cc’d the correct emails so the agency (DLA) could be provided with the correct MIPR that they were requesting. It was of upmost importance for the agency to receive that MIPR so we could receive and process the 448-2 acceptance with urgency. \n",
       "\n",
       "#### Miguel Vega\n",
       "- Assisted a colleague in gathering necessary 3 DAI reports and 1 Maximo report in order to send out a Cost Transfer in a timely fashion.\n",
       "- Completed a hot item that my Supervisor and lead needed immediately: contract PR’s for a CMTSS contract for goods. I was able to demonstrate the ability to remain calm and focused under pressure and submit the document without any mistakes so the document could be signed as soon as possible. I stayed until the task was completed and the supervisor was informed. \n",
       "- Worked on the Status of Funds for FY22 as well as FY23 and verified that there were no funds remaining. Upon accessing DAI and gathering the data, I communicated my findings to my supervisor and edited the Status of Funds data so my supervisor could easily see and read the gathered information. \n",
       "- Completed 2 contract PRs for goods for 20K. I was able to provide a solution to my supervisor. One of my colleagues who was in charge of creating those PRs continued to get an error message. I was able to create 2 PRs with my supervisor looking on to see if they could see it in PD2. The creation of the PR’s was a success and was able to be seen in PD2. Since it is the close of the FY we could not afford to delay due to in-corrections. The corrections were able to be made and did not delay the process. \n",
       "- Worked on assisting my supervisor in looking for a specific MIPR that was on the Open Commitment Pivot Tables I pull and create every morning. I was provided the correct email chain and cc’d the correct emails so the agency (DLA) could be provided with the correct MIPR that they were requesting. It was of upmost importance for the agency to receive that MIPR so we could receive and process the 448-2 acceptance with urgency. \n",
       "\n",
       "---\n",
       "\n",
       "## Deliverables Completed  \n",
       "- Monthly Status Report  \n",
       "- Provided administrative and financial services support.\n",
       "\n",
       "---\n",
       "\n",
       "## Highlights  \n",
       "- None\n",
       "\n",
       "---\n",
       "\n",
       "## Issues/Resolutions  \n",
       "- **Issue:** None  \n",
       "- **Resolution:** None\n",
       "\n",
       "---\n",
       "\n",
       "## Planned Work for Next Two Months  \n",
       "- Continued administrative and financial services support.\n",
       "\n",
       "---\n",
       "\n",
       "## Leave  \n",
       "| Name           | Planned Leave September | Planned Leave October |\n",
       "|----------------|-------------------------|-----------------------|\n",
       "| Eddy Biniam  | NA                      | NA                    |\n",
       "| Miguel Vega | NA                     | NA                    |\n",
       "\n",
       "---\n",
       "\n",
       "## Recommendations  \n",
       "- None\n",
       "\n",
       "---\n",
       "\n",
       "## Contractual/Staffing Actions  \n",
       "- None\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import pypandoc\n",
    "\n",
    "# File processing functions\n",
    "def read_word_file(file_path: str) -> str:\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def process_input_docs(directory: str) -> Dict[str, str]:\n",
    "    input_docs = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            content = read_word_file(file_path)\n",
    "            input_docs[filename] = content\n",
    "    return input_docs\n",
    "\n",
    "# Prompt management functions\n",
    "def load_prompt(prompt_name: str) -> str:\n",
    "    prompt_folder = \"./prompt_folder\"\n",
    "    os.makedirs(prompt_folder, exist_ok=True)\n",
    "    prompt_path = os.path.join(prompt_folder, f\"{prompt_name}.txt\")\n",
    "    \n",
    "    if os.path.exists(prompt_path):\n",
    "        with open(prompt_path, 'r') as file:\n",
    "            return file.read()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def save_prompt(prompt_name: str, prompt_content: str):\n",
    "    prompt_folder = \"./prompt_folder\"\n",
    "    os.makedirs(prompt_folder, exist_ok=True)\n",
    "    prompt_path = os.path.join(prompt_folder, f\"{prompt_name}.txt\")\n",
    "    \n",
    "    with open(prompt_path, 'w') as file:\n",
    "        file.write(prompt_content)\n",
    "\n",
    "# Setup Gemini AI\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "# Generate monthly status report\n",
    "def generate_monthly_status_report(master_content: str, example_content: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with creating a Monthly Status Report based on the following information:\n",
    "\n",
    "    1. Master File Content (combined MSR files):\n",
    "    {master_content}\n",
    "\n",
    "    2. Example Report Format (example of a combined MSR file output):\n",
    "    {example_content}\n",
    "\n",
    "    Please generate a Monthly Status Report following the structure and style of the example report, \n",
    "    using the information provided in the master file. \n",
    "    - Ensure that you maintain the accuracy of the information from the master file (only fix grammar, do not change the information)\n",
    "    - Follow the formatting of the example report.\n",
    "    - Make sure to seperated the work of each person.\n",
    "    \n",
    "    Use Markdown to represent the following:\n",
    "    - Headings\n",
    "    - Bullet points\n",
    "    - Bold for emphasis\n",
    "    - Tables where applicable\n",
    "    \n",
    "    Your generated report should be comprehensive, accurate, and well-structured in Markdown format.\n",
    "    \"\"\"\n",
    "    save_prompt(\"monthly_status_report\", prompt)\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt, stream=True)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for chunk in response:\n",
    "            if chunk.text:\n",
    "                full_response += chunk.text\n",
    "        \n",
    "        # Handling Safety Filters\n",
    "        if response.candidates[0].finish_reason == \"SAFETY\":\n",
    "            safety_ratings = response.candidates[0].safety_ratings\n",
    "            safety_message = \"Content was filtered due to safety concerns:\\n\"\n",
    "            for rating in safety_ratings:\n",
    "                safety_message += f\"- Category: {rating.category}, Probability: {rating.probability}\\n\"\n",
    "            print(safety_message)\n",
    "            return safety_message\n",
    "        \n",
    "        # Retrieving Usage Metadata\n",
    "        if hasattr(response, 'usage_metadata'):\n",
    "            prompt_tokens = response.usage_metadata.prompt_token_count\n",
    "            candidates_tokens = response.usage_metadata.candidates_token_count\n",
    "            print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "            print(f\"Response tokens: {candidates_tokens}\")\n",
    "        \n",
    "        return full_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {e}\"\n",
    "        print(error_message)\n",
    "        return error_message\n",
    "\n",
    "# File saving and conversion functions\n",
    "def save_markdown_to_file(markdown_content: str, file_path: str):\n",
    "    with open(file_path, 'w') as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "def convert_markdown_to_docx(markdown_file_path: str, output_file_path: str):\n",
    "    pypandoc.convert_file(markdown_file_path, 'docx', outputfile=output_file_path)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Process input documents\n",
    "    input_directory = \"./data_files/inputs/TO4_LeasesFacilitiesDivision(LFD)\"\n",
    "    processed_docs = process_input_docs(input_directory)\n",
    "    \n",
    "    # Export into a text file in the data_files/master_file folder\n",
    "    os.makedirs(\"./data_files/master_file\", exist_ok=True)\n",
    "    output_file = \"./data_files/master_file/master_file.txt\"\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for filename, content in processed_docs.items():\n",
    "            file.write(f\"File: {filename}\\n\")\n",
    "            file.write(f\"Content: {content}\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")\n",
    "            file.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"Combined documents exported to: {output_file}\")\n",
    "    \n",
    "    # Read the master file and example file\n",
    "    with open(\"./data_files/master_file/master_file.txt\", 'r') as file:\n",
    "        master_content = file.read()\n",
    "    \n",
    "    with open(\"./example/example.txt\", 'r') as file:\n",
    "        example_content = file.read()\n",
    "    \n",
    "    # Generate the monthly status report in Markdown\n",
    "    report = generate_monthly_status_report(master_content, example_content)\n",
    "\n",
    "    # Save the Markdown report\n",
    "    markdown_file = \"./generated_report.md\"\n",
    "    save_markdown_to_file(report, markdown_file)\n",
    "\n",
    "    # Convert the Markdown report to Word document\n",
    "    docx_file = \"./generated_report.docx\"\n",
    "    convert_markdown_to_docx(markdown_file, docx_file)\n",
    "\n",
    "    print(f\"Monthly Status Report has been generated and saved to '{docx_file}'\")\n",
    "\n",
    "    # Display the generated report (if running in a Jupyter notebook)\n",
    "    with open(\"generated_report.md\", 'r') as md_file:\n",
    "        generated_report_content = md_file.read()\n",
    "    display(Markdown(generated_report_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
